---
title: "Statistical Analysis"
output: 
  html_document:
    toc: true
    toc_float: true 
    code_folding: hide 
editor_options: 
  chunk_output_type: console
---

Here is some additional analysis of the data set.

First, the same loading and cleaning method was used. 

```{r message=FALSE, warning=FALSE, include=FALSE}

library(tidyverse)
library(janitor)
library(lubridate)
library(crosstalk)
library(htmltools)
library(DT)
library(modelr) 
library(mgcv) 
library(tidytext)
library(wordcloud)
library(RColorBrewer)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
  )


```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE}
airplane_df = read_csv("datasets/airplane_crashes_data.csv", show_col_types = FALSE) |>
  clean_names() |>
  filter(ground != "NULL", aboard != "NULL") |>
  select(-flight_number, -time, -registration)
```

```{r, echo=FALSE}
airplane_df = airplane_df |> 
  mutate(
  
    date = str_trim(date),
    
      m = as.numeric(sub("/.*", "", date)),                    
    d = as.numeric(sub(".*/(.*)/.*", "\\1", date)),          
    y = as.numeric(sub(".*/(.*)$", "\\1", date)),            
    
    y = ifelse(y < 100, y + 1900, y),
    
    date_clean = paste(m, d, y, sep = "/"),
    
    date = mdy(date_clean),
    
    year = year(date),
    month = month(date),
    month_name = factor(month(date, 
                              label = TRUE, 
                              abbr = TRUE), 
                              levels = month.abb)
  ) |>
  select(-m, -d, -y, -date_clean) 
```

```{r, echo=FALSE}
airplane_df = airplane_df |>
  mutate(
    aboard     = as.numeric(aboard),
    fatalities = as.numeric(fatalities),
    ground     = as.numeric(ground),
    operator   = as.factor(operator)
  )
```

```{r echo = FALSE}
airplane_df = airplane_df |> 
  mutate(
    decade = floor(year / 10) * 10, 
    decade = paste0(decade, "s")
  ) |> 
  select(date, year, decade, month, month_name, everything()) 

geocoded_locations = read_csv("datasets/geocoded_cache.csv", show_col_types = FALSE)

df_map <- airplane_df |>
  left_join(geocoded_locations, by = c("location" = "location_clean")) |>
  filter(!is.na(Latitude), !is.na(Longitude))
```
--- 
## Does the average number of crash events differs across months?

To investigate potential seasonal trends in aviation safety, we selected data from Northern Hemisphere and plot the accident per month. We then performed a One-Way ANOVA to determine if the average number of airplane crashes differs significantly across the months.

The ANOVA results yielded a p-value of 0.039, which was below the 0.05 significance level. Although, the average number of crashes per month is small, so even a few events can create "significant" differences.

```{r anova for seaonal crashes per year}

airplane_north = df_map |>
  filter(aboard > 0, !is.na(fatalities))|>
   filter(Latitude> 0)|> 
  mutate(
    survival_rate = (aboard - fatalities) / aboard,
    month_num     = month(date),
    season = case_when(
      month_num %in% c(12, 1, 2)  ~ "Winter",
      month_num %in% c(3, 4, 5)   ~ "Spring",
      month_num %in% c(6, 7, 8)   ~ "Summer",
      month_num %in% c(9, 10, 11) ~ "Fall"
    )
  ) |>
  filter(!is.na(season)) |>
  mutate(season = fct_relevel(season, "Spring", "Summer", "Fall", "Winter"))

cat("=== ANOVA result ===\n")
airplane_north |> 
  # Count crashes per year/season combo
  count(year, month, name = "crash_count")|>

# ANOVA 
aov(crash_count ~ factor(month), data = _) |> 
  summary()

# ---- plot ----
 airplane_north |> 
  count(year, month, name = "crash_count")|>
  group_by(month) |>
  summarise(
    mean_crashes = mean(crash_count),
    se = sd(crash_count) / sqrt(n())
  ) |>
  ggplot(aes(x = month, y = mean_crashes)) +
  scale_x_continuous(breaks = 1:12) +
  geom_col(fill = "steelblue",show.legend = FALSE) +
  geom_errorbar(aes(ymin = mean_crashes - se,
                    ymax = mean_crashes + se),
                width = 0.15) +
  labs(
    title = "Average Airplane Crashes in Northern Hemisphere per Month",
        x = "Month",
    y = "Average Crash Count"
  ) +
  theme_minimal()

```

We also test for the differences of fatality rate across months. BUt there is no significant evidence suggested a monthly difference of fatality rate.

```{r anova for season and fatality}

cat("=== ANOVA result ===\n")

airplane_north|>
 ##ANOVA
aov(survival_rate ~ factor(month), data = _ )|>
summary()


```
## Is the fatality rate lower over time?

To evaluate the long-term trend in survivability, we plot the fatality rates per year. Statistical evidence confirmed that airplanes have become safer over time regarding rate of survival. Linear regression analysis revealed a statistically significant negative correlation between year and fatality rate (p < 0.001). 

However, the low R-squared value (0.015) indicated that while the downward trend is consistent, the outcome of any individual crash is heavily influenced by situational factors other than just the time period, and the average fatality rate of a single year is still largely determined by random effect.

```{r lm year ~ fatality}

 airplane_df |> 
  filter(aboard > 0, !is.na(fatalities)) |> 
  mutate(fatality_rate = fatalities / aboard) |> 
  group_by(year) |> 
  summarise(mean_fatality_rate = mean(fatality_rate)) |> 
  ggplot(aes(x = year, y = mean_fatality_rate)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", fill = "pink",se = TRUE) +
   scale_x_continuous(breaks = seq(1910, 2010, by = 10) 
  )+
  labs(
    title = "Trend in Airplane Fatality Rate Over Time",,
    x = "Year",
    y = "Average Fatality Rate"
  ) +
  theme_minimal()

 airplane_df |> 
  filter(aboard > 0, !is.na(fatalities)) |> 
  mutate(fatality_rate = fatalities / aboard) |> 
  group_by(year) |> 
  summarise(mean_fatality_rate = mean(fatality_rate))|> 
 lm(mean_fatality_rate ~ year, data = _)|> summary()

```


## Are the number of crash events higher or lower over the years?

To describe the historical trend of aviation safety, we aggregated the total number of crashes per year. We then fitted a simple linear regression model and Loess model to determine if there was a statistically significant linear increase or decrease in crash frequency over the recorded time period (1908â€“2009).
With a medium fitted model, the linear regression analysis revealed a statistically significant upward trend.But this failed to accurately describe the crash events overtime, LOESS could reveal more specific fluctuations and details in history.

```{r}

crashes_by_year = airplane_df |> 
  count(year, name = "total_crashes")

ggplot(crashes_by_year, aes(x = year, y = total_crashes)) +
  geom_point(color = "steelblue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", fill = "pink", se = TRUE, span = 0.2)+
  geom_smooth(method = "loess", color = "royalblue", fill = "lightblue", se = TRUE, span = 0.2) +
  scale_x_continuous(breaks = seq(1910, 2010, by = 10) 
  ) +
  labs(
    title = "Trend of Total Airplane Crashes per Year",
    subtitle = "Red: Linear Trend | Blue: LOESS Trend",
    x = "Year",
    y = "Total Number of Crashes"
  ) +
  theme_minimal()

fit_count_linear = lm(total_crashes ~ year, data = crashes_by_year)
summary(fit_count_linear)

```
The visual comparison demonstrated the limitations of the linear model. The linear fit failed to capture the mid-century rise and the late-century decline in crashes, resulting in high systematic error. The LOESS model provides the superior fit account for historical fluctuations and recent down trend.

## What could be the causes?

To see the causes and recurring themes of aviation incidents, we performed text mining on the crash summary descriptions. After tokenizing the text and removing common stop words (e.g., 'the', 'and',"plane","crashed") and numbers, we generated a Word Cloud.

```{r word cloud }
word_counts = airplane_df |> 
  filter(!is.na(summary)) |> 
  select(date, summary) |> 
  unnest_tokens(word, summary) |> 
  anti_join(stop_words) |> 
  filter(!str_detect(word, "^[0-9]"))  |> 
  filter(word != "crashed", word != "plane", word !="aircraft", word != "flight")|>
  count(word, sort = TRUE) 

set.seed(1234)

wordcloud(
  words = word_counts$word,      
  freq = word_counts$n,          
  min.freq = 10,                 
  max.words = 100,               
  random.order = FALSE,          
  rot.per = 0.25,   
  colors = brewer.pal(9, "Blues")[5:9]
)
```



